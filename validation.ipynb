{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# step4: validation "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### validation imageset --> patch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### validation set for validation\n",
    "import glob\n",
    "import cv2\n",
    "validation_images = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"./data/nocrop/val/*.png\"))]\n",
    "print(validation_images[0].shape)\n",
    "print(len(validation_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## validation 이미지(정상28, 결함52--> 총 80개)를 patch tensor로 만들어줌\n",
    "## validation_patches: 80, 256, 64, 64\n",
    "validation_patches = patch(validation_images)"
   ]
  },
  {
   "source": [
    "### original image & reconstructed images visualization\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "AE based on CNN 모델이 제대로 패치 이미지를 reconstruct하는지 확인하기 위해\n",
    "visualization하는 코드\n",
    "\"\"\"\n",
    "def visualization(model_num, validation_patches):\n",
    "  device = 'cpu'\n",
    "  ## model load\n",
    "  models = [Autoencoder1().to(device), Autoencoder2().to(device), \n",
    "            Autoencoder3().to(device), Autoencoder4().to(device)]\n",
    "  new_model= models[model_num-1]\n",
    "  new_model.load_state_dict(torch.load(\"./model/finalepoch/Autoencoder{}.pth\".format(model_num)))\n",
    "  \n",
    "  new_model.eval()\n",
    "\n",
    "  img_idx = 0\n",
    "  ## 한 이미지에 들어있는 patch들을 매 loop마다 불러온다. \n",
    "  ## 즉, 256개의 패치를 256, 64, 64 사이즈의 텐서로 불러온다.\n",
    "  for patch in validation_patches:\n",
    "    if img_idx < 53:\n",
    "      img_idx += 1 \n",
    "      continue\n",
    "    # 예시로 defect 이미지 하나에 대한 patch들을 출력한다.\n",
    "    elif img_idx == 53:\n",
    "      ## 각 패치를 매 loop마다 불러온다.\n",
    "      for patch_idx in range(256):\n",
    "        original = patch[patch_idx].view(1,1,64,64)\n",
    "        original = Variable(original).cpu()\n",
    "\n",
    "        pred = new_model(original)\n",
    "        pred = pred.view(64, 64).detach()\n",
    "\n",
    "        ## original 패치 이미지 출력\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.title(\"Original\")\n",
    "        plt.imshow(np.transpose(original.view(64,64), (0,1))*255.,cmap='gray', vmin=0, vmax=255)\n",
    "        ## reconstructed 패치 이미지 출력\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.title(\"Reconstructed\")\n",
    "        plt.imshow(np.transpose(pred,(0,1))*255.,cmap='gray', vmin=0, vmax=255)\n",
    "        plt.show()\n",
    "        img_idx += 1\n",
    "    else:\n",
    "      break\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch로 잘라내기 이전의 원본 이미지\n",
    "plt.imshow(validation_images[53].view(256,4096), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1\n",
    "# Input original image -> AE -> Reconstructed image\n",
    "visualization(1, validation_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2\n",
    "# Input original image -> AE -> Reconstructed image\n",
    "visualization(2, validation_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model3\n",
    "# Input original image -> AE -> Reconstructed image\n",
    "visualization(3, validation_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model4\n",
    "# Input original image -> AE -> Reconstructed image\n",
    "visualization(4, validation_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model5 # cnn stride를 키웠을 때 재구성이 잘 되지않음. --> 모델 채택 x\n",
    "# Input original image -> AE -> Reconstructed image\n",
    "visualization(5, validation_patches)"
   ]
  },
  {
   "source": [
    "### validation function \n",
    "- load model\n",
    "- patch defectness detect(by patch_threshold)\n",
    "- image defectness detect(by patch_num_threshold)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "defect로 판단된 patch 개수가 threshold이상이면,\n",
    "해당 이미지를 defect로 판단하여 True를 return한다.\n",
    "\"\"\"\n",
    "def image_prediction(patch_num_threshold, defectness_list):\n",
    "  defect_num = sum(defectness_list)\n",
    "  if (defect_num >= patch_num_threshold):\n",
    "    return True # defect patch가 k개 이상이면, 해당 이미지는 defect(True)\n",
    "  return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "patch 한 개에 대한 loss값이 threshold이상이면,\n",
    "해당 patch를 defect를 판단하여 True를 return한다.\n",
    "\"\"\"\n",
    "def patch_prediction(loss, patch_threshold):\n",
    "  if loss >= patch_threshold :\n",
    "    return True\n",
    "  else: \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "validation의 역할\n",
    "1. patch threshold, image threshold 설정\n",
    "2. 모델 성능평가: \n",
    "   model4개에 대해 patch threshold 3가지, image threshold 3가지를 적용\n",
    "  --> f1 score가 가장 높은 모델과 threshold 선택\n",
    "\"\"\"\n",
    "def validation(model_num, validation_patches, k, threshold, cm):\n",
    "\n",
    "  TP = 0\n",
    "  TN = 0\n",
    "  FN = 0 \n",
    "  FP = 0\n",
    "  img_idx = 0\n",
    "  loss_func = nn.MSELoss()\n",
    "  models = [Autoencoder1().to(device), Autoencoder2().to(device), \n",
    "            Autoencoder3().to(device), Autoencoder4().to(device)]\n",
    "  new_model= models[model_num-1]\n",
    "  new_model.load_state_dict(torch.load(\"./model/model{}/Autoencoder{}_epoch19.pth\".format(model_num,model_num)))\n",
    "  \n",
    "  new_model.eval()\n",
    "  y_true=[]\n",
    "  y_pred=[]\n",
    "  \n",
    "  ## 한 이미지에 들어있는 patch들을 매 loop마다 불러온다. \n",
    "  ## 즉, 256개의 패치를 256, 64, 64 사이즈의 텐서로 불러온다.\n",
    "  for patch in validation_patches:\n",
    "\n",
    "    ## 원본 이미지들의 true label을 y_true에 저장\n",
    "    if img_idx<28:\n",
    "        y_true.append(0) #정상\n",
    "    else:\n",
    "        y_true.append(1)\n",
    "    defectness_list = []\n",
    "    \n",
    "    ## 각 패치를 매 loop마다 불러온다.\n",
    "    for patch_idx in range(256):\n",
    "      one_patch = patch[patch_idx].view(1,1,64,64)\n",
    "      one_patch = Variable(one_patch).cuda()\n",
    "      pred = new_model(one_patch)\n",
    "      loss = loss_func(pred, one_patch)\n",
    "      # 각 patch의 결함여부가 T / F값으로 저장됨\n",
    "      defectness = patch_prediction(loss, threshold ) \n",
    "      defectness_list.append(defectness)\n",
    "    # 각 이미지의 결함여부가 T / F값으로 저장됨\n",
    "    image_defectness = image_prediction(k, defectness_list)\n",
    "\n",
    "    if img_idx < 28: # 실제 정상\n",
    "      if image_defectness == True: #결함 판단(오류)\n",
    "        FN += 1\n",
    "        y_pred.append(1)\n",
    "      else: # 정상 판단\n",
    "        TN += 1\n",
    "        y_pred.append(0)\n",
    "    else: # 실제 결함\n",
    "      if image_defectness == True: # 결함 판단\n",
    "        TP += 1\n",
    "        y_pred.append(1)\n",
    "      else: # 정상 판단(오류)\n",
    "        FP += 1 # want to minimize\n",
    "        y_pred.append(0)\n",
    "   \n",
    "    img_idx += 1\n",
    "\n",
    "  print(\"true:  정상  결함\")\n",
    "  print(\"pred: \", TN, \" \", FP)\n",
    "  print(\"      \", FN, \" \", TP)\n",
    "\n",
    "  f1score = f1_score(y_true, y_pred)\n",
    "  accuracy = accuracy_score(y_true, y_pred)\n",
    "  print(\"f1score=\", f1score)\n",
    "  print(\"accuracy=\", accuracy)\n",
    "  \n",
    "  if cm == True:\n",
    "    confusion_matrix2= confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(confusion_matrix2.T, annot=True,fmt='d',\n",
    "                xticklabels=['nodefect','defect'], yticklabels=['nodefect','defect'], cmap=\"YlGnBu\")\n",
    "    plt.xlabel('true')\n",
    "    plt.ylabel('predicted')\n",
    "    plt.title('Confusion Matirx', fontsize=20)\n",
    "\n",
    "  return f1score # 높을수록 성능 good \n"
   ]
  },
  {
   "source": [
    "```\n",
    "\n",
    "\"\"\"\n",
    "    REAL        정상              결함\n",
    "PRED\n",
    "정상      TN(정상-정상판단) FP(결함-정상판단)\n",
    "결함      FN(정상-결함판단) TP(결함-결함판단)\n",
    "\"\"\"\n",
    "```\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모델마다 9가지의 f1score를 저장\n",
    "\n",
    "model_f1score =  torch.zeros(4,3,3)\n",
    "image_threshold = [3,5,7]\n",
    "patch_threshold = [0.0028, 0.005, 0.01]\n",
    "# 모델 1~4\n",
    "for model_num in range(1,5):\n",
    "  print()\n",
    "  print()\n",
    "  print(\"model: Autoencoder\", model_num)\n",
    "  ## grid search\n",
    "  # image_threshold 값이 하나씩 들어간다.\n",
    "  for k in range(len(image_threshold)):\n",
    "    # patch_threshold 값이 하나씩 들어간다.\n",
    "    for j in range(len(patch_threshold)):\n",
    "      print(\"image_threshold: \", image_threshold[k], \"patch_threshold: \", patch_threshold[j])\n",
    "      model_f1score[model_num-1][k][j] = validation(model_num, validation_patches, image_threshold[k], patch_threshold[j], False)\n",
    "\n",
    "print(model_f1score)"
   ]
  },
  {
   "source": [
    "** best:model 4 **\n",
    "- image_threshold:  3\n",
    "- patch_threshold:  0.0028\n",
    "- f1score= 0.8793"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model의 Confusion matrix 출력\n",
    "validation(4, validation_patches, 3, 0.0028, True)"
   ]
  }
 ]
}